{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/jpanalian/miniconda3/envs/deeplearning/lib/python3.7/site-packages/botocore/vendored/requests/packages/urllib3/_collections.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, MutableMapping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "import argparse\n",
    "import mlflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "seaborn.set_style('whitegrid')\n",
    "seaborn.set_palette('colorblind')\n",
    "seaborn.set_context('paper')\n",
    "\n",
    "DATA_DIRECTORY = './petfinder_dataset/'\n",
    "TARGET_COL = 'AdoptionSpeed'\n",
    " \n",
    "SHUFFLE_BUFFER_SIZE = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_dir):\n",
    "\n",
    "    # Read train dataset (and maybe dev, if you need to...)\n",
    "    dataset, dev_dataset = train_test_split(\n",
    "        pandas.read_csv(os.path.join(dataset_dir, 'train.csv')), test_size=0.2)\n",
    "         \n",
    "    test_dataset = pandas.read_csv(os.path.join(dataset_dir, 'test.csv'))\n",
    "    \n",
    "    print('Training samples {}, test_samples {}'.format(\n",
    "        dataset.shape[0], test_dataset.shape[0]))\n",
    "    \n",
    "    return dataset, dev_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_features(df, one_hot_columns, numeric_columns, embedded_columns, test=False):\n",
    "    direct_features = []\n",
    "\n",
    "    # Create one hot encodings\n",
    "    for one_hot_col, max_value in one_hot_columns.items():\n",
    "        direct_features.append(tf.keras.utils.to_categorical(df[one_hot_col] - 1, max_value))\n",
    "       \n",
    "    \n",
    "    # Concatenate all features that don't need further embedding into a single matrix.\n",
    "    features = {'direct_features': numpy.hstack(direct_features)}\n",
    "\n",
    "    # Create embedding columns - nothing to do here. We will use the zero embedding for OOV\n",
    "    for embedded_col in embedded_columns.keys():\n",
    "        features[embedded_col] = df[embedded_col].values\n",
    "\n",
    "    # Agregado por JPA -- Create and append numeric columns - Don't forget to normalize!\n",
    "    for n_col in numeric_columns:\n",
    "        features[n_col] =  df[n_col].values - df[n_col].mean() / df[n_col].std()\n",
    "        \n",
    "    if not test:\n",
    "        nlabels = df[TARGET_COL].unique().shape[0]\n",
    "        # Convert labels to one-hot encodings\n",
    "        targets = tf.keras.utils.to_categorical(df[TARGET_COL], nlabels)\n",
    "    else:\n",
    "        targets = None\n",
    "    \n",
    "    return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples 8465, test_samples 4411\n"
     ]
    }
   ],
   "source": [
    "dataset, dev_dataset, test_dataset = load_dataset(DATA_DIRECTORY)\n",
    "nlabels = dataset[TARGET_COL].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_columns = {\n",
    "        one_hot_col: dataset[one_hot_col].max()\n",
    "        for one_hot_col in ['Type','Gender', 'Color1','Color2', 'Color3','MaturitySize','Vaccinated','Dewormed', 'Sterilized','Health', 'State']\n",
    "}\n",
    "\n",
    "embedded_columns = {\n",
    "        embedded_col: dataset[embedded_col].max() + 1\n",
    "        for embedded_col in ['Breed1','Breed2'] \n",
    "}\n",
    "\n",
    "numeric_columns = ['Age', 'Fee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "X_train, y_train = process_features(dataset, one_hot_columns, numeric_columns, embedded_columns)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(BATCH_SIZE).shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "\n",
    "X_dev, y_dev = process_features(dev_dataset, one_hot_columns, numeric_columns, embedded_columns)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_dev, y_dev)).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kagg, y_kagg = process_features(test_dataset, one_hot_columns, numeric_columns, embedded_columns, test=True)\n",
    "\n",
    "kagg_ds = tf.data.Dataset.from_tensor_slices(X_kagg).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'Age': <tf.Tensor: id=62, shape=(100,), dtype=float64, numpy=\n",
      "array([47.42715085,  1.42715085, 35.42715085,  0.42715085,  2.42715085,\n",
      "       11.42715085,  3.42715085,  4.42715085,  3.42715085,  5.42715085,\n",
      "       11.42715085,  1.42715085,  5.42715085, 35.42715085,  3.42715085,\n",
      "        2.42715085,  1.42715085,  9.42715085,  2.42715085, 83.42715085,\n",
      "        0.42715085,  6.42715085,  4.42715085,  1.42715085,  0.42715085,\n",
      "        1.42715085,  3.42715085, 23.42715085,  2.42715085,  1.42715085,\n",
      "        1.42715085,  1.42715085,  3.42715085, 13.42715085,  1.42715085,\n",
      "        1.42715085,  1.42715085,  2.42715085, 47.42715085,  1.42715085,\n",
      "        3.42715085,  0.42715085,  5.42715085,  3.42715085,  2.42715085,\n",
      "        5.42715085,  2.42715085,  1.42715085,  1.42715085,  0.42715085,\n",
      "        3.42715085, 17.42715085,  2.42715085,  0.42715085,  1.42715085,\n",
      "        2.42715085, 11.42715085,  2.42715085,  2.42715085,  2.42715085,\n",
      "        1.42715085,  0.42715085, 23.42715085,  3.42715085, 11.42715085,\n",
      "        5.42715085, 35.42715085,  9.42715085,  2.42715085, 59.42715085,\n",
      "       11.42715085,  7.42715085,  2.42715085,  7.42715085,  0.42715085,\n",
      "        1.42715085,  0.42715085,  1.42715085,  2.42715085,  1.42715085,\n",
      "        6.42715085, 11.42715085,  6.42715085, 23.42715085, 83.42715085,\n",
      "        7.42715085,  1.42715085,  1.42715085,  1.42715085,  5.42715085,\n",
      "       95.42715085,  1.42715085,  1.42715085,  0.42715085,  3.42715085,\n",
      "        7.42715085,  2.42715085,  1.42715085, 29.42715085,  1.42715085])>,\n",
      "  'Breed1': <tf.Tensor: id=63, shape=(100,), dtype=int64, numpy=\n",
      "array([266, 307, 307, 265, 307, 307, 307, 307, 266, 266, 265, 266, 266,\n",
      "       307, 307, 243, 307, 266, 307, 100, 266, 266, 266, 307, 266, 299,\n",
      "       307, 307, 307, 266, 254, 264, 247, 307, 266, 266, 266, 307, 182,\n",
      "       307, 265, 266, 299, 307, 307, 307, 307, 265, 265, 307, 266, 266,\n",
      "       243, 224, 265, 266, 307, 307, 189, 307, 307, 128, 265, 266, 266,\n",
      "       265, 231, 307, 266, 307, 307, 205, 266, 292,  71, 292, 266, 307,\n",
      "       292, 307, 307, 265, 266, 266, 266, 266, 218, 251, 266, 293, 165,\n",
      "        26, 307, 307, 295, 307, 307, 307, 265, 266])>,\n",
      "  'Breed2': <tf.Tensor: id=64, shape=(100,), dtype=int64, numpy=\n",
      "array([  0,   0, 228,   0,   0, 119,   0,   0,   0, 266, 299,   0,   0,\n",
      "         0, 117,   0, 307,   0, 103,   0,   0,   0,   0, 103,   0,   0,\n",
      "       218, 307,   0,   0, 265,   0, 292,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0, 292, 307,   0,   0,\n",
      "         0, 307,   0,   0,   0,   0, 307,   0,   0, 307,   0,   0,   0,\n",
      "         0, 307, 307, 299,   0,   0, 218,   0,   0, 307,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0, 307, 266,   0,   0,   0,\n",
      "       307, 307, 307,   0,   0,   0, 218,   0, 266])>,\n",
      "  'Fee': <tf.Tensor: id=65, shape=(100,), dtype=float64, numpy=\n",
      "array([-2.63429214e-01, -2.63429214e-01,  1.49736571e+02, -2.63429214e-01,\n",
      "       -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,  9.97365708e+01,\n",
      "       -2.63429214e-01, -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,\n",
      "        9.97365708e+01, -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,\n",
      "       -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,  9.97365708e+01,\n",
      "       -2.63429214e-01, -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,\n",
      "       -2.63429214e-01, -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,\n",
      "       -2.63429214e-01, -2.63429214e-01,  4.97365708e+01,  2.97365708e+01,\n",
      "        9.97365708e+01, -2.63429214e-01,  1.97365708e+01, -2.63429214e-01,\n",
      "       -2.63429214e-01, -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,\n",
      "        2.99736571e+02,  4.97365708e+01, -2.63429214e-01,  3.49736571e+02,\n",
      "       -2.63429214e-01, -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,\n",
      "       -2.63429214e-01, -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,\n",
      "       -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,  4.97365708e+01,\n",
      "       -2.63429214e-01, -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,\n",
      "       -2.63429214e-01, -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,\n",
      "       -2.63429214e-01, -2.63429214e-01,  1.99736571e+02, -2.63429214e-01,\n",
      "       -2.63429214e-01, -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,\n",
      "       -2.63429214e-01, -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,\n",
      "       -2.63429214e-01, -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,\n",
      "        9.97365708e+01,  1.99736571e+02, -2.63429214e-01,  4.97365708e+01,\n",
      "       -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,  9.97365708e+01,\n",
      "        1.97365708e+01, -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,\n",
      "       -2.63429214e-01, -2.63429214e-01, -2.63429214e-01, -2.63429214e-01,\n",
      "       -2.63429214e-01, -2.63429214e-01,  7.36570786e-01, -2.63429214e-01])>,\n",
      "  'direct_features': <tf.Tensor: id=66, shape=(100, 41457), dtype=float32, numpy=\n",
      "array([[0., 1., 1., ..., 0., 0., 0.],\n",
      "       [1., 0., 1., ..., 0., 0., 0.],\n",
      "       [1., 0., 1., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [1., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 1., 0., ..., 0., 0., 0.],\n",
      "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)>},\n",
      " <tf.Tensor: id=67, shape=(100, 5), dtype=float32, numpy=\n",
      "array([[0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.]], dtype=float32)>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for data in train_ds.take(1):  # The dataset only returns a data instance now (no target)\n",
    "    pprint(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding embedding of size 77 for layer Breed1\n",
      "Adding embedding of size 77 for layer Breed2\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_LAYER_SIZE = 36\n",
    "DIRECT_FEATURES_INPUT_SHAPE = (X_train['direct_features'].shape[1],)\n",
    "DROPOUT_RATE = 0.25\n",
    "\n",
    "# Add one input and one embedding for each embedded column\n",
    "embedding_layers = []\n",
    "inputs = []\n",
    "\n",
    "for embedded_col, max_value in embedded_columns.items():\n",
    "    input_layer = layers.Input(shape=(1,), name=embedded_col)\n",
    "    inputs.append(input_layer)\n",
    "    # Define the embedding layer\n",
    "    embedding_size = int(max_value / 4)\n",
    "    embedding_layers.append(\n",
    "        tf.squeeze(layers.Embedding(input_dim=max_value, output_dim=embedding_size)(input_layer), axis=-2))\n",
    "    \n",
    "    print('Adding embedding of size {} for layer {}'.format(embedding_size, embedded_col))\n",
    "\n",
    "# Add the direct features already calculated\n",
    "direct_features_input = layers.Input(shape=DIRECT_FEATURES_INPUT_SHAPE, name='direct_features')\n",
    "inputs.append(direct_features_input)\n",
    "            \n",
    "# Concatenate everything together\n",
    "features = layers.concatenate(embedding_layers + [direct_features_input])\n",
    "\n",
    "dense1 = layers.Dense(HIDDEN_LAYER_SIZE, activation='relu')(features)\n",
    "\n",
    "drop1 = layers.Dropout(DROPOUT_RATE)(dense1)\n",
    "\n",
    "dense2 = layers.Dense(HIDDEN_LAYER_SIZE / 2, activation='relu')(drop1)\n",
    "\n",
    "drop2 = layers.Dropout(DROPOUT_RATE)(dense2)\n",
    "\n",
    "dense3 = layers.Dense(HIDDEN_LAYER_SIZE / 4, activation='relu')(drop2)\n",
    "\n",
    "output_layer = layers.Dense(nlabels, activation='softmax')(dense3)\n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Breed1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Breed2 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 77)        23716       Breed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 77)        23716       Breed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 77)]         0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_1 (TensorFl [(None, 77)]         0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "direct_features (InputLayer)    [(None, 41457)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 41611)        0           tf_op_layer_Squeeze[0][0]        \n",
      "                                                                 tf_op_layer_Squeeze_1[0][0]      \n",
      "                                                                 direct_features[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 36)           1498032     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 36)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 18)           666         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 18)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 9)            171         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5)            50          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,546,351\n",
      "Trainable params: 1,546,351\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"702pt\" viewBox=\"0.00 0.00 724.50 702.00\" width=\"725pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 698)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-698 720.5,-698 720.5,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140164783269776 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140164783269776</title>\n",
       "<polygon fill=\"none\" points=\"64,-657.5 64,-693.5 187,-693.5 187,-657.5 64,-657.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"125.5\" y=\"-671.8\">Breed1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140165390091344 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140165390091344</title>\n",
       "<polygon fill=\"none\" points=\"51.5,-584.5 51.5,-620.5 199.5,-620.5 199.5,-584.5 51.5,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"125.5\" y=\"-598.8\">embedding: Embedding</text>\n",
       "</g>\n",
       "<!-- 140164783269776&#45;&gt;140165390091344 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140164783269776-&gt;140165390091344</title>\n",
       "<path d=\"M125.5,-657.4551C125.5,-649.3828 125.5,-639.6764 125.5,-630.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"129.0001,-630.5903 125.5,-620.5904 122.0001,-630.5904 129.0001,-630.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140165390143952 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140165390143952</title>\n",
       "<polygon fill=\"none\" points=\"340,-657.5 340,-693.5 463,-693.5 463,-657.5 340,-657.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401.5\" y=\"-671.8\">Breed2: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140164783271184 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140164783271184</title>\n",
       "<polygon fill=\"none\" points=\"321,-584.5 321,-620.5 482,-620.5 482,-584.5 321,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401.5\" y=\"-598.8\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 140165390143952&#45;&gt;140164783271184 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140165390143952-&gt;140164783271184</title>\n",
       "<path d=\"M401.5,-657.4551C401.5,-649.3828 401.5,-639.6764 401.5,-630.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"405.0001,-630.5903 401.5,-620.5904 398.0001,-630.5904 405.0001,-630.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140164783218256 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140164783218256</title>\n",
       "<polygon fill=\"none\" points=\"0,-511.5 0,-547.5 251,-547.5 251,-511.5 0,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"125.5\" y=\"-525.8\">tf_op_layer_Squeeze: TensorFlowOpLayer</text>\n",
       "</g>\n",
       "<!-- 140165390091344&#45;&gt;140164783218256 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140165390091344-&gt;140164783218256</title>\n",
       "<path d=\"M125.5,-584.4551C125.5,-576.3828 125.5,-566.6764 125.5,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"129.0001,-557.5903 125.5,-547.5904 122.0001,-557.5904 129.0001,-557.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140164783218384 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140164783218384</title>\n",
       "<polygon fill=\"none\" points=\"269,-511.5 269,-547.5 534,-547.5 534,-511.5 269,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401.5\" y=\"-525.8\">tf_op_layer_Squeeze_1: TensorFlowOpLayer</text>\n",
       "</g>\n",
       "<!-- 140164783271184&#45;&gt;140164783218384 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140164783271184-&gt;140164783218384</title>\n",
       "<path d=\"M401.5,-584.4551C401.5,-576.3828 401.5,-566.6764 401.5,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"405.0001,-557.5903 401.5,-547.5904 398.0001,-557.5904 405.0001,-557.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140164783326224 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>140164783326224</title>\n",
       "<polygon fill=\"none\" points=\"324,-438.5 324,-474.5 479,-474.5 479,-438.5 324,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401.5\" y=\"-452.8\">concatenate: Concatenate</text>\n",
       "</g>\n",
       "<!-- 140164783218256&#45;&gt;140164783326224 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140164783218256-&gt;140164783326224</title>\n",
       "<path d=\"M193.7247,-511.4551C232.9524,-501.0796 282.3878,-488.0043 323.1959,-477.2109\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"324.331,-480.5311 333.1036,-474.5904 322.541,-473.7638 324.331,-480.5311\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140164783218384&#45;&gt;140164783326224 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>140164783218384-&gt;140164783326224</title>\n",
       "<path d=\"M401.5,-511.4551C401.5,-503.3828 401.5,-493.6764 401.5,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"405.0001,-484.5903 401.5,-474.5904 398.0001,-484.5904 405.0001,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140164783269840 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140164783269840</title>\n",
       "<polygon fill=\"none\" points=\"552.5,-511.5 552.5,-547.5 716.5,-547.5 716.5,-511.5 552.5,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"634.5\" y=\"-525.8\">direct_features: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140164783269840&#45;&gt;140164783326224 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>140164783269840-&gt;140164783326224</title>\n",
       "<path d=\"M576.9045,-511.4551C544.2785,-501.2332 503.2882,-488.3907 469.1388,-477.6916\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"469.8295,-474.2403 459.2405,-474.5904 467.7366,-480.9201 469.8295,-474.2403\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140164783327440 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>140164783327440</title>\n",
       "<polygon fill=\"none\" points=\"357,-365.5 357,-401.5 446,-401.5 446,-365.5 357,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401.5\" y=\"-379.8\">dense: Dense</text>\n",
       "</g>\n",
       "<!-- 140164783326224&#45;&gt;140164783327440 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>140164783326224-&gt;140164783327440</title>\n",
       "<path d=\"M401.5,-438.4551C401.5,-430.3828 401.5,-420.6764 401.5,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"405.0001,-411.5903 401.5,-401.5904 398.0001,-411.5904 405.0001,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140164783328464 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>140164783328464</title>\n",
       "<polygon fill=\"none\" points=\"346,-292.5 346,-328.5 457,-328.5 457,-292.5 346,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401.5\" y=\"-306.8\">dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 140164783327440&#45;&gt;140164783328464 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>140164783327440-&gt;140164783328464</title>\n",
       "<path d=\"M401.5,-365.4551C401.5,-357.3828 401.5,-347.6764 401.5,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"405.0001,-338.5903 401.5,-328.5904 398.0001,-338.5904 405.0001,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140164783336848 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>140164783336848</title>\n",
       "<polygon fill=\"none\" points=\"350.5,-219.5 350.5,-255.5 452.5,-255.5 452.5,-219.5 350.5,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401.5\" y=\"-233.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140164783328464&#45;&gt;140164783336848 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>140164783328464-&gt;140164783336848</title>\n",
       "<path d=\"M401.5,-292.4551C401.5,-284.3828 401.5,-274.6764 401.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"405.0001,-265.5903 401.5,-255.5904 398.0001,-265.5904 405.0001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140164783050064 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>140164783050064</title>\n",
       "<polygon fill=\"none\" points=\"339,-146.5 339,-182.5 464,-182.5 464,-146.5 339,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401.5\" y=\"-160.8\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 140164783336848&#45;&gt;140164783050064 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>140164783336848-&gt;140164783050064</title>\n",
       "<path d=\"M401.5,-219.4551C401.5,-211.3828 401.5,-201.6764 401.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"405.0001,-192.5903 401.5,-182.5904 398.0001,-192.5904 405.0001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140164782997776 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>140164782997776</title>\n",
       "<polygon fill=\"none\" points=\"350.5,-73.5 350.5,-109.5 452.5,-109.5 452.5,-73.5 350.5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401.5\" y=\"-87.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 140164783050064&#45;&gt;140164782997776 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>140164783050064-&gt;140164782997776</title>\n",
       "<path d=\"M401.5,-146.4551C401.5,-138.3828 401.5,-128.6764 401.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"405.0001,-119.5903 401.5,-109.5904 398.0001,-119.5904 405.0001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140164782341776 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>140164782341776</title>\n",
       "<polygon fill=\"none\" points=\"350.5,-.5 350.5,-36.5 452.5,-36.5 452.5,-.5 350.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401.5\" y=\"-14.8\">dense_3: Dense</text>\n",
       "</g>\n",
       "<!-- 140164782997776&#45;&gt;140164782341776 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>140164782997776-&gt;140164782341776</title>\n",
       "<path d=\"M401.5,-73.4551C401.5,-65.3828 401.5,-55.6764 401.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"405.0001,-46.5903 401.5,-36.5904 398.0001,-46.5904 405.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, dpi=72).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "85/85 [==============================] - 4s 47ms/step - loss: 1.5444 - accuracy: 0.2385\n",
      "Epoch 2/12\n",
      "85/85 [==============================] - 3s 36ms/step - loss: 1.4878 - accuracy: 0.2641\n",
      "Epoch 3/12\n",
      "85/85 [==============================] - 3s 39ms/step - loss: 1.4717 - accuracy: 0.2877\n",
      "Epoch 4/12\n",
      "85/85 [==============================] - 3s 36ms/step - loss: 1.4646 - accuracy: 0.2882\n",
      "Epoch 5/12\n",
      "85/85 [==============================] - 3s 38ms/step - loss: 1.4519 - accuracy: 0.3103\n",
      "Epoch 6/12\n",
      "85/85 [==============================] - 3s 39ms/step - loss: 1.4455 - accuracy: 0.3120\n",
      "Epoch 7/12\n",
      "85/85 [==============================] - 3s 37ms/step - loss: 1.4306 - accuracy: 0.3302\n",
      "Epoch 8/12\n",
      "85/85 [==============================] - 3s 38ms/step - loss: 1.4204 - accuracy: 0.3438\n",
      "Epoch 9/12\n",
      "85/85 [==============================] - 3s 37ms/step - loss: 1.4094 - accuracy: 0.3494\n",
      "Epoch 10/12\n",
      "85/85 [==============================] - 3s 37ms/step - loss: 1.3994 - accuracy: 0.3565\n",
      "Epoch 11/12\n",
      "85/85 [==============================] - 3s 37ms/step - loss: 1.3940 - accuracy: 0.3649\n",
      "Epoch 12/12\n",
      "85/85 [==============================] - 3s 39ms/step - loss: 1.3882 - accuracy: 0.3740\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 1.4007 - accuracy: 0.3576\n",
      "*** Test loss: 1.4006551937623457 - accuracy: 0.3575814962387085\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment('tp1_corrida_04')\n",
    "\n",
    "with mlflow.start_run(nested=True):\n",
    "    # Log model hiperparameters first\n",
    "    mlflow.log_param('hidden_layer_size', HIDDEN_LAYER_SIZE)\n",
    "    mlflow.log_param('embedded_columns', embedded_columns)\n",
    "    mlflow.log_param('one_hot_columns', one_hot_columns)\n",
    "    mlflow.log_param('numerical_columns', numeric_columns)  \n",
    "    mlflow.log_param('train_dataset.shuffke', True)  \n",
    "    mlflow.log_param('dropout', DROPOUT_RATE)\n",
    "    # Train\n",
    "    epochs = 12\n",
    "    history = model.fit(train_ds, epochs=epochs)\n",
    "    \n",
    "    # Evaluate\n",
    "    loss, accuracy = model.evaluate(test_ds)\n",
    "    print(\"*** Test loss: {} - accuracy: {}\".format(loss, accuracy))\n",
    "    mlflow.log_metric('epochs', epochs)\n",
    "    mlflow.log_metric('loss', loss)\n",
    "    mlflow.log_metric('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluando del modelo\n",
    "Además de tener en cuenta las métricas de performance del modelo, es importante mirar los resultados obtenidos y controlar que el modelo efectivamente está aprendiendo algo relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/jpanalian/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py:364: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  if isinstance(inputs, collections.Sequence):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7b087984d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = numpy.argmax(model.predict(test_ds), axis=1)\n",
    "seaborn.countplot(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pandas.DataFrame( list(zip( test_dataset['PID'], numpy.argmax(model.predict(kagg_ds), axis=1))), \n",
    "                              columns=[\"PID\", \"AdoptionSpeed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(DATA_DIRECTORY + \"submission_out_3.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [1.5051638558991056, 1.4517754504332794, 1.4312456727943264, 1.4165737319823488, 1.4107639279790833, 1.4025469274825058, 1.3965387455612968, 1.3925882392709803, 1.3878408738021941, 1.3811526878726461, 1.3797700268519537, 1.3753422985961292, 1.3717566620859956, 1.3656208940462045, 1.365171435382052], 'accuracy': [0.28375664, 0.31234494, 0.33845246, 0.3509746, 0.34790313, 0.35534555, 0.358417, 0.36030716, 0.3679858, 0.36975783, 0.37188423, 0.3760189, 0.37341997, 0.3868872, 0.3862965]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_chief_worker_only',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " 'epoch',\n",
       " 'history',\n",
       " 'model',\n",
       " 'on_batch_begin',\n",
       " 'on_batch_end',\n",
       " 'on_epoch_begin',\n",
       " 'on_epoch_end',\n",
       " 'on_predict_batch_begin',\n",
       " 'on_predict_batch_end',\n",
       " 'on_predict_begin',\n",
       " 'on_predict_end',\n",
       " 'on_test_batch_begin',\n",
       " 'on_test_batch_end',\n",
       " 'on_test_begin',\n",
       " 'on_test_end',\n",
       " 'on_train_batch_begin',\n",
       " 'on_train_batch_end',\n",
       " 'on_train_begin',\n",
       " 'on_train_end',\n",
       " 'params',\n",
       " 'set_model',\n",
       " 'set_params',\n",
       " 'validation_data']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning] *",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
